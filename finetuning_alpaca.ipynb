{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Low Rank Adaptation and Parameter Efficient Finetuning of HuggingFace Alpaca LLMs on Text Summarisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Relevant Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings, torch, json, random, gc\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import (\n",
    "    LlamaTokenizer,\n",
    "    LlamaForCausalLM,\n",
    "    DataCollatorForSeq2Seq, \n",
    "    Trainer, \n",
    "    TrainingArguments, \n",
    ")\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_int8_training,\n",
    "    TaskType,\n",
    "    PeftModel,\n",
    "    PeftConfig\n",
    ")\n",
    "from rouge import Rouge\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import Dict, Iterable\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ[\"LLM_REPOSITORY\"] = \"chavinlo/alpaca-native\"\n",
    "os.environ[\"TOKENIZER_REPOSITORY\"] = \"chavinlo/alpaca-native\"\n",
    "os.environ[\"EMBEDDINGS_MODEL\"] = \"all-MiniLM-L12-v2\"\n",
    "os.environ[\"MAX_TOKENS\"] = \"4096\"\n",
    "os.environ[\"DEVICE\"] = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "os.environ[\"DATASET_PATH\"] = \"data/doc_summary_data\"\n",
    "os.environ[\"TOKENS_DATA_PATH\"] = F\"data/doc_summary_{os.environ['TOKENIZER_REPOSITORY'].split('/')[-1]}_tokens\"\n",
    "os.environ[\"SUMMARY_DATA_PATH\"] = \"data/doc_summary_pair.json\"\n",
    "os.makedirs(os.environ[\"DATASET_PATH\"], exist_ok=True)\n",
    "os.makedirs(os.environ[\"TOKENS_DATA_PATH\"], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DATA PREPARATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset into Training, Validation and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_SIZE = 0.8\n",
    "VALIDATION_SIZE = 0.1\n",
    "TEST_SIZE = 0.1\n",
    "\n",
    "with open(os.environ[\"SUMMARY_DATA_PATH\"]) as f:\n",
    "    doc_summary_data = json.load(f)\n",
    "f.close()\n",
    "\n",
    "random.shuffle(doc_summary_data)\n",
    "train_size = int(len(doc_summary_data) * TRAIN_SIZE)\n",
    "val_size = int(len(doc_summary_data) * VALIDATION_SIZE)\n",
    "test_size = int(len(doc_summary_data) * TEST_SIZE)\n",
    "\n",
    "train_data = doc_summary_data[:train_size]\n",
    "val_data = doc_summary_data[train_size:train_size+val_size]\n",
    "test_data = doc_summary_data[train_size+val_size:]\n",
    "\n",
    "data_list = [\n",
    "    (\"train\", train_data),\n",
    "    (\"validation\", val_data),\n",
    "    (\"test\", test_data),\n",
    "]\n",
    "\n",
    "for data_tuple in data_list:\n",
    "    _file_path = os.path.join(os.environ[\"DATASET_PATH\"], f\"{data_tuple[0]}.json\")\n",
    "    if not os.path.exists(_file_path):\n",
    "        with open(_file_path, \"w\") as f:\n",
    "            json.dump(data_tuple[1], f, indent=4)\n",
    "        f.close()\n",
    "\n",
    "del doc_summary_data, train_data, val_data, test_data, data_list, data_tuple, train_size, val_size, test_size\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset into DictDataset Format to be modelled by the HuggingFace LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eedbcb80afa547778b47df3c70ee0d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c76048fc0943d190cb35ef9147c5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4fe88805c924bcf9012dcbf8c8fcd4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75210bf72034aabb8d5398159b35aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "067e6882e2c64f77855ddd33d3cb2fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 4000\n",
      "Validation dataset size: 500\n",
      "Test dataset size: 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'summary': 'This study is trying to find the highest dose of a drug that can be tolerated by monitoring the occurrence of severe toxicities related to the drug. The maximum tolerated dose will be determined based on when these toxicities occur within 28 days of the first vaccine injection.',\n",
       " 'id': 1127,\n",
       " 'document': 'DL2, and 23 months and 13 days for DL3.|Number of Participants With Dose-Limiting Toxicities (DLT), Dose-limiting toxicity (DLT) will be defined as any one of the following: Any grade ≥ 3 hematologic toxicity or grade ≥ 3 non-hematologic toxicity that is possibly, probably, or definitely related to study drug, except transient (≤ 48 hour) grade 3 fatigue, local reactions, flu-like symptoms, fever, headache, and laboratory abnormalities that are not associated with organ pathology. Also any ≥ grade 2 allergic and ≥ grade 2 autoimmune reaction(s) (except endocrine-related immune toxicity) will be defined as a DLT. Any grade 3 autoimmune endocrine-related toxicity that has not resolved clinically within 7 days of initiating therapy will also be defined as a DLT. Generalized erythroderma or macular or papular rash lasting less than 7 days and not associated with desquamation will not be DLTs., 28 days following the first injection of vaccine.|Maximum Tolerated Dose (MTD), The MTD will be the dose level at which'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(path=os.environ[\"DATASET_PATH\"])\n",
    "print(f\"Train dataset size: {len(dataset['train'])}\")\n",
    "print(f\"Validation dataset size: {len(dataset['validation'])}\")\n",
    "print(f\"Test dataset size: {len(dataset['test'])}\")\n",
    "dataset[\"train\"][random.randint(0, len(dataset[\"train\"]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Corresponding LLM Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(\n",
    "    os.environ[\"TOKENIZER_REPOSITORY\"],\n",
    "    model_max_length=int(os.environ[\"MAX_TOKENS\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Tokenizer Object to retreive the Maximum Source (Text) and Target (Summary) Tokens in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237f9f44a92a47e9a7b8eddf0bbeb8e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4361f5ac954adda4727a5684e4413b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max source length: 550\n",
      "Max target length: 317\n"
     ]
    }
   ],
   "source": [
    "concatenated_dataset = concatenate_datasets(\n",
    "    [dataset[\"train\"], dataset[\"validation\"], dataset[\"test\"]]\n",
    ")\n",
    "tokenized_inputs = concatenated_dataset.map(\n",
    "    lambda x: tokenizer(x[\"document\"], truncation=True), batched=True, remove_columns=[\"document\", \"summary\"])\n",
    "\n",
    "tokenized_targets = concatenated_dataset.map(\n",
    "    lambda x: tokenizer(x[\"summary\"], truncation=True), batched=True, remove_columns=[\"document\", \"summary\"])\n",
    "\n",
    "max_source_length = max([len(x) for x in tokenized_inputs[\"input_ids\"]]) + 64\n",
    "max_target_length = max([len(x) for x in tokenized_targets[\"input_ids\"]]) + 64\n",
    "\n",
    "print(f\"Max source length: {max_source_length}\")\n",
    "print(f\"Max target length: {max_target_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Dataset and Persist Tokens to Disk Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c241bdee929a46f89a39b6de01dc1961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e4847bd7ee43f38ca0dbb26e0b4f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc1298783e7448da1edbb28bca81f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of tokenized dataset: ['input_ids', 'attention_mask', 'labels']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756dada43f664a71ac97269392206b1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4287e331492047d29c1807f6e25f3e84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0909bb9918f74d029de961f1c103fcec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LABEL_PAD_TOKEN_ID = -100\n",
    "TRAIN_ON_INPUT = False\n",
    "generate_prompt = lambda document : (\n",
    "    \"Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\"\n",
    "    f\"Generate a concise summary of this document:\\n\\n DOCUMENT: \\n{document} \\n\\n SUMMARY:\"\n",
    ")\n",
    "def preprocess_function(\n",
    "    sample, \n",
    "    max_seq_length: int, \n",
    "    padding: str=\"max_length\", \n",
    "    train_on_input: bool=False):\n",
    "    \n",
    "    _input = f\"{generate_prompt(sample['document'])} {sample['summary']}\"\n",
    "    tokenization_result = tokenizer(\n",
    "        _input,\n",
    "        max_length=max_seq_length, \n",
    "        padding=False,\n",
    "        truncation=True,\n",
    "    )\n",
    "    input_tokens = tokenization_result[\"input_ids\"].copy()\n",
    "    label_tokens = tokenization_result[\"input_ids\"].copy()\n",
    "    \n",
    "    if not train_on_input:\n",
    "        prompt_tokens = tokenizer(\n",
    "            generate_prompt(sample['document']),\n",
    "            max_length=max_seq_length, \n",
    "            padding=False,\n",
    "            truncation=True,\n",
    "        )[\"input_ids\"]\n",
    "        prompt_tokens_len = len(prompt_tokens)\n",
    "        input_tokens = input_tokens[:prompt_tokens_len]\n",
    "        label_tokens = ([LABEL_PAD_TOKEN_ID]*prompt_tokens_len) + label_tokens[prompt_tokens_len:]\n",
    "        input_tokens = input_tokens + [tokenizer.pad_token_id]*(len(label_tokens)-prompt_tokens_len)\n",
    "        \n",
    "    else:\n",
    "        input_tokens.append(tokenizer.eos_token_id)\n",
    "        \n",
    "    tokenization_result[\"input_ids\"] = input_tokens\n",
    "    tokenization_result[\"labels\"] = label_tokens\n",
    "    tokenization_result[\"attention_mask\"] = [1]*len(input_tokens)\n",
    "    return tokenization_result\n",
    "\n",
    "preprocess_lambda = lambda dataset : preprocess_function(\n",
    "    dataset, \n",
    "    sum([max_source_length, max_target_length]),\n",
    "    train_on_input=TRAIN_ON_INPUT,\n",
    ")\n",
    "# batched arg must be set to False for this to work properly\n",
    "tokenized_dataset = dataset.map(preprocess_lambda, batched=False, remove_columns=[\"document\", \"summary\", \"id\"])\n",
    "print(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")\n",
    "\n",
    "# save datasets to disk for later easy loading\n",
    "tokenized_dataset[\"train\"].save_to_disk(os.path.join(os.environ[\"TOKENS_DATA_PATH\"], \"train\"))\n",
    "tokenized_dataset[\"validation\"].save_to_disk(os.path.join(os.environ[\"TOKENS_DATA_PATH\"], \"validation\"))\n",
    "tokenized_dataset[\"test\"].save_to_disk(os.path.join(os.environ[\"TOKENS_DATA_PATH\"], \"test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MODEL PREPARATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load 8bits quantized HuggingFace LLM to Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952af7ac1b6641799f9016b0dfd1c63a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define model\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=os.environ[\"LLM_REPOSITORY\"],\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Low Rank Adaptation Configurations Object and apply to Loaded LLM for Parameter Efficient Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 8,388,608 || all params: 6,746,812,416 || trainable%: 0.12433438908285782\n"
     ]
    }
   ],
   "source": [
    "# Define LoRA Config \n",
    "lora_config = LoraConfig(\n",
    " r=16, \n",
    " lora_alpha=32,\n",
    " target_modules=[\"q_proj\", \"v_proj\"],\n",
    " lora_dropout=0.05,\n",
    " bias=\"none\",\n",
    " task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "# prepare int-8 model for training\n",
    "model = prepare_model_for_int8_training(model)\n",
    "\n",
    "# add LoRA adaptor\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Data Collator Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=LABEL_PAD_TOKEN_ID,\n",
    "    pad_to_multiple_of=8,\n",
    "     padding=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MODEL FINETUNING / TRAINING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Seq2SeqTrainer Object and Commence LoRA Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9974' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 9974/10000 22:45:38 < 03:33, 0.12 it/s, Epoch 19.95/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.846200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.430600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>4.204500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.993200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.780400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.566800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>3.336100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.095100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>2.840900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.578400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>2.317800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.049200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.781500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.530300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.305900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.102800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.916300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.753800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.612100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "OUTPUT_DIR = F\"lora-{os.environ['LLM_REPOSITORY'].split('/')[-1]}\"\n",
    "NUM_EPOCHS = 20\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# Define training args\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "\tauto_find_batch_size=True,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    logging_dir=os.path.join(OUTPUT_DIR, \"logs\"),\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=500,\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"tensorboard\",\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    ")\n",
    "model.config.use_cache = False  # to be set to True for inference\n",
    "\n",
    "# finetune model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist LoRA Model Weights to Disk Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our LoRA model & tokenizer results\n",
    "PEFT_MODEL_ID=f\"{os.environ['LLM_REPOSITORY'].split('/')[-1]}_finetuned_results\"\n",
    "trainer.model.save_pretrained(PEFT_MODEL_ID)\n",
    "tokenizer.save_pretrained(PEFT_MODEL_ID)\n",
    "\n",
    "# # delete model and tokenizer from memory\n",
    "del model, tokenizer\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MODEL EVALUATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load LoRA Weights from Disk to Perform Inference on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2657add64ed44715b33fb945148fb130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load peft config for pre-trained checkpoint etc. \n",
    "config = PeftConfig.from_pretrained(PEFT_MODEL_ID)\n",
    "\n",
    "# load base LLM model and tokenizer\n",
    "model = LlamaForCausalLM.from_pretrained(config.base_model_name_or_path,  load_in_8bit=True,  device_map=\"auto\")\n",
    "tokenizer = LlamaTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "# Load the Lora model\n",
    "model = PeftModel.from_pretrained(model, PEFT_MODEL_ID, device_map=\"auto\", torch_dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Summaries from Documents in Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: States|Helen F Graham Cancer Center, Newark, Delaware, 19713, United States|University of Florida Health Science Center - Gainesville, Gainesville, Florida, 32610, United States|Memorial Regional Hospital/Joe DiMaggio Children's Hospital, Hollywood, Florida, 33021, United States|Mayo Clinic in Florida, Jacksonville, Florida, 32224-9980, United States|Miami Cancer Institute, Miami, Florida, 33176, United States|Orlando Health Cancer Institute, Orlando, Florida, 32806, United States|Memorial Hospital West, Pembroke Pines, Florida, 33028, United States|Emory University Hospital Midtown, Atlanta, Georgia, 30308, United States|Piedmont Hospital, Atlanta, Georgia, 30309, United States|Emory University Hospital/Winship Cancer Institute, Atlanta, Georgia, 30322, United States|Emory Saint Joseph's Hospital, Atlanta, Georgia, 30342, United States|John B Amos Cancer Center, Columbus, Georgia, 31904, United States|CTCA at Southeastern Regional Medical Center, Newnan, Georgia, 30265, United States|Lewis Hall Singletary\n",
      "\n",
      "SUMARY:  The list provides a list of cancer centers and hospitals in various states across the United States. Some of them are specific to one city or region while others are more general in nature. Each center has a unique story to tell and offers something different for visitors. From medical centers specializing in natural healing, to hospitals that offer spiritual guidance, each center has its own distinct personality. It is up to the visitor to decide which one suits their cup of tea.\n",
      "\n",
      "\n",
      "Document: Southeastern Regional Medical Center, Newnan, Georgia, 30265, United States|Lewis Hall Singletary Oncology Center, Thomasville, Georgia, 31792, United States|Queen's Medical Center, Honolulu, Hawaii, 96813, United States|The Cancer Center of Hawaii-Liliha, Honolulu, Hawaii, 96817, United States|Northwestern University, Chicago, Illinois, 60611, United States|Rush University Medical Center, Chicago, Illinois, 60612, United States|University of Illinois, Chicago, Illinois, 60612, United States|University of Chicago Comprehensive Cancer Center, Chicago, Illinois, 60637, United States|Decatur Memorial Hospital, Decatur, Illinois, 62526, United States|Northwestern Medicine Cancer Center Delnor, Geneva, Illinois, 60134, United States|Loyola University Medical Center, Maywood, Illinois, 60153, United States|Methodist Medical Center of Illinois, Peoria, Illinois, 61636, United States|Memorial Medical Center, Springfield, Illinois, 62781, United States|Southwest Illinois Health Services LLP, Swansea, Illinois, 62226,\n",
      "\n",
      "SUMARY:  The list includes a list of medical centers in the United States, the state of Hawaii, and Chicago. The list includes the name of the medical center, location, city, and state. The medical centers are listed in alphabetical order from A to Z. The list also includes a brief description of each center. Some of the medical centers have a link to their website for further information.\n",
      "\n",
      "\n",
      "Document: Illinois, 62781, United States|Southwest Illinois Health Services LLP, Swansea, Illinois, 62226, United States|Carle Cancer Center, Urbana, Illinois, 61801, United States|Northwestern Medicine Cancer Center Warrenville, Warrenville, Illinois, 60555, United States|Midwestern Regional Medical Center, Zion, Illinois, 60099, United States|Ascension Saint Vincent Anderson, Anderson, Indiana, 46016, United States|Parkview Hospital Randallia, Fort Wayne, Indiana, 46805, United States|Parkview Regional Medical Center, Fort Wayne, Indiana, 46845, United States|IU Health Ball Memorial Hospital, Muncie, Indiana, 47303, United States|Memorial Hospital of South Bend, South Bend, Indiana, 46601, United States|Ascension Via Christi Hospitals Wichita, Wichita, Kansas, 67214, United States|Owensboro Health Mitchell Memorial Cancer Center, Owensboro, Kentucky, 42303, United States|MaineHealth Coastal Cancer Treatment Center, Bath, Maine, 04530, United States|MaineHealth/SMHC Cancer Care and Blood Disorders-Biddeford,\n",
      "\n",
      "SUMARY:  The list includes healthcare centers in the United States, Illinois, and Kentucky, and Kansas. Each state has multiple treatment centers. The first three states have links to their respective websites provided for your convenience. The last two states have links to their respective websites as well. The website for each state provides detailed information about services offered, including contact information, hours, location, and special offers. Some offer online appointment scheduling capabilities, while others require you to call or email for an appointment. Please note that some of these websites may not be fully accessible from all countries.\n",
      "\n",
      "The list also includes a link to a comprehensive list of cancer treatments. This list will help you find additional resources for cancer treatments related to the various types of cancer, such as chemother treatments, surgery, and radiation treatments. It is important to remember that this list is not exhaustive and there may be other treatments not listed here. Additionally, the list does not include any treatments that involve drugs, soaps, or other products.\n",
      "\n",
      "\n",
      "Document: Bath, Maine, 04530, United States|MaineHealth/SMHC Cancer Care and Blood Disorders-Biddeford, Biddeford, Maine, 04005, United States|Maine Medical Center-Bramhall Campus, Portland, Maine, 04102, United States|MaineHealth Cancer Care Center of York County, Sanford, Maine, 04073, United States|MaineHealth/SMHC Cancer Care and Blood Disorders-Sanford, Sanford, Maine, 04073, United States|Maine Medical Center- Scarborough Campus, Scarborough, Maine, 04074, United States|University of Maryland/Greenebaum Cancer Center, Baltimore, Maryland, 21201, United States|Greater Baltimore Medical Center, Baltimore, Maryland, 21204, United States|UM Upper Chesapeake Medical Center, Bel Air, Maryland, 21014, United States|Central Maryland Radiation Oncology in Howard County, Columbia, Maryland, 21044, United States|Lahey Hospital and Medical Center, Burlington, Massachusetts, 01805, United States|Lowell General Hospital, Lowell, Massachusetts, 01854, United States|University of Michigan Comprehensive Cancer Center, Ann Arbor,\n",
      "\n",
      "SUMARY:  This list provides a comprehensive list of cancer centers in the United States. The list includes all states and cities within the United States. Each state is listed with its corresponding city or town. The list also includes each city in the order in which they are located. It is important to note that some cities may have more than one center, while others may only have one. Some cities may even contain multiple centers. In addition, some cities may have more than one center, which could mean there are multiple centers within the same city. Therefore, it is important to be aware of this when searching for a specific center.\n",
      "\n",
      "The list does not include any centers outside of the United States. The list does not include any centers located in Canada, Mexico, or other countries. It does not include any centers located on other planets. It does not include any centers located on the moon. It does not include any centers located on other planets. It does not include any centers located on other planets. It does not include any centers located on other planets. It does not include any centers located on other planets. It does not include any centers located on other planets. It does not include any\n",
      "\n",
      "\n",
      "Document: Massachusetts, 01854, United States|University of Michigan Comprehensive Cancer Center, Ann Arbor, Michigan, 48109, United States|Henry Ford Cancer Institute-Downriver, Brownstown, Michigan, 48183, United States|GenesisCare USA - Clarkston, Clarkston, Michigan, 48346, United States|Henry Ford Macomb Hospital-Clinton Township, Clinton Township, Michigan, 48038, United States|Henry Ford Hospital, Detroit, Michigan, 48202, United States|GenesisCare USA - Farmington Hills, Farmington Hills, Michigan, 48334, United States|West Michigan Cancer Center, Kalamazoo, Michigan, 49007, United States|Saint Joseph Mercy Oakland, Pontiac, Michigan, 48341, United States|William Beaumont Hospital-Royal Oak, Royal Oak, Michigan, 48073, United States|GenesisCare USA - Troy, Troy, Michigan, 48098, United States|Henry Ford West Bloomfield Hospital, West Bloomfield, Michigan, 48322, United States|Mercy Hospital, Coon Rapids, Minnesota, 55433, United States|Saint Luke's Hospital of Duluth, Duluth, Minnesota, 55805, United\n",
      "\n",
      "SUMARY:  The list includes a list of hospitals from different states. It also includes some hospitals from other countries. The list includes the name of the hospital, location, city or town, and the state. There are a few hospitals from both states and countries on the list. Some of them are general hospitals, while others are specialized in areas such as matern, mental health, or children’s services. The list does not include any information about the specific services offered by the hospital. It does not provide any details about the quality of care, nor does it provide any information about the quality of life within the hospital. It does not provide any information about the quality of life for patients, nor does it provide any information about the quality of life for their families. The list does not include any information about the quality of life for the community or the environment. It does not provide any information about the quality of life for the planet, nor does it provide any information about the quality of life for its employees. The list does not include any information about the quality of life for the animals in the area, nor does it provide any information about the quality of life for the trees and plants in the area. The list does not include any information\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_summaries = []\n",
    "n_docs = 5\n",
    "input_documents = dataset[\"test\"][\"document\"][:n_docs]\n",
    "target_summaries = dataset[\"test\"][\"summary\"][:n_docs]\n",
    "\n",
    "model.eval()\n",
    "for i, document in enumerate(input_documents):\n",
    "    prompt = generate_prompt(document)\n",
    "    prompt_tokens = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    summary_tokens = model.generate(\n",
    "        **prompt_tokens,\n",
    "        return_dict_in_generate=True,\n",
    "        temperature=0.1,\n",
    "        top_p=0.15,\n",
    "        top_k=0,\n",
    "        repetition_penalty=1.1,\n",
    "        max_new_tokens=256,\n",
    "    )\n",
    "    summary = tokenizer.decode(summary_tokens.sequences[0], skip_special_tokens=True)\n",
    "    print(f\"Document: {document}\\n\")\n",
    "    print(f\"SUMARY: {summary.replace(prompt, '').replace('</s>', '')}\\n\\n\")\n",
    "    predicted_summaries.append(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PERFORMANCE MEASUREMENT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Generated Summaries to Target Summaries with the Rouge Score and the Cosine Similarity Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity for summary 1: 0.7862063 \n",
      "\n",
      "Rouge scores for summary 1: {'rouge-1': {'r': 0.72, 'p': 0.12, 'f': 0.20571428326530614}, 'rouge-2': {'r': 0.35714285714285715, 'p': 0.047619047619047616, 'f': 0.08403361136925362}, 'rouge-l': {'r': 0.56, 'p': 0.09333333333333334, 'f': 0.15999999755102043}} \n",
      "\n",
      "\n",
      "Cosine similarity for summary 2: 0.67372495 \n",
      "\n",
      "Rouge scores for summary 2: {'rouge-1': {'r': 0.5238095238095238, 'p': 0.09482758620689655, 'f': 0.16058393901006981}, 'rouge-2': {'r': 0.22727272727272727, 'p': 0.02824858757062147, 'f': 0.05025125431479011}, 'rouge-l': {'r': 0.5238095238095238, 'p': 0.09482758620689655, 'f': 0.16058393901006981}} \n",
      "\n",
      "\n",
      "Cosine similarity for summary 3: 0.747568 \n",
      "\n",
      "Rouge scores for summary 3: {'rouge-1': {'r': 0.6, 'p': 0.06060606060606061, 'f': 0.11009174145273967}, 'rouge-2': {'r': 0.05263157894736842, 'p': 0.0034129692832764505, 'f': 0.00641025526647785}, 'rouge-l': {'r': 0.5, 'p': 0.050505050505050504, 'f': 0.09174311759952868}} \n",
      "\n",
      "\n",
      "Cosine similarity for summary 4: 0.73609066 \n",
      "\n",
      "Rouge scores for summary 4: {'rouge-1': {'r': 0.5652173913043478, 'p': 0.08024691358024691, 'f': 0.1405405383631848}, 'rouge-2': {'r': 0.125, 'p': 0.012552301255230125, 'f': 0.02281368655438142}, 'rouge-l': {'r': 0.43478260869565216, 'p': 0.06172839506172839, 'f': 0.10810810593075242}} \n",
      "\n",
      "\n",
      "Cosine similarity for summary 5: 0.43769848 \n",
      "\n",
      "Rouge scores for summary 5: {'rouge-1': {'r': 0.7142857142857143, 'p': 0.06329113924050633, 'f': 0.11627906827203896}, 'rouge-2': {'r': 0.14285714285714285, 'p': 0.00816326530612245, 'f': 0.015444014421371248}, 'rouge-l': {'r': 0.5714285714285714, 'p': 0.05063291139240506, 'f': 0.09302325431855057}} \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "embeddings_model = SentenceTransformer(os.environ[\"EMBEDDINGS_MODEL\"])\n",
    "embeddings_model.to(os.environ[\"DEVICE\"])\n",
    "_zipped_data = zip(input_documents, predicted_summaries, target_summaries)\n",
    "\n",
    "for i, (document, predicted_summary, target_summary) in enumerate(_zipped_data):\n",
    "    prompt = generate_prompt(document)\n",
    "    pred_embeddings, target_embeddings = (\n",
    "        embeddings_model.encode(predicted_summary.replace(prompt, '').replace('</s>', '')).reshape(1, -1),\n",
    "        embeddings_model.encode(target_summary.replace(prompt, '').replace('</s>', '')).reshape(1, -1)\n",
    "    )\n",
    "    cos_similarity = cosine_similarity(target_embeddings, pred_embeddings)\n",
    "    rouge_scores = rouge.get_scores(predicted_summary, target_summary)\n",
    "    print(f\"Cosine similarity for summary {i+1}:\", cos_similarity[0][0], \"\\n\")\n",
    "    print(f\"Rouge scores for summary {i+1}:\", rouge_scores[0], \"\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
